<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="32">
            <Title>Regular expresions</Title>
            <Text>After the boilerplate text is removed from the raw data, regular expressions are used to remove a broader range of useless data. Dates and times found in the raw data are not useful for classifying and solving problems, so they are removed. If temporal information was desired it could be extracted from the database in a uniform format. During this step special characters are also removed and white spaces are compressed.</Text>
            <Comments>In script ie_preproc_c.py</Comments>
        </Document>
        <Document ID="25">
            <Title>Conclusions and Future Work</Title>
        </Document>
        <Document ID="40">
            <Title>Machine Learning</Title>
        </Document>
        <Document ID="33">
            <Title>Statement</Title>
            <Text>Most large corporations provide various information technologies to their workers. To support the provided hardware and software they often have a help desk or service desk which is made up of people and software. Service desk employees are often entry level and have little understanding of the business and its specific technical problems, so software is employed to route tickets to the appropriate staff and record the knowledge which is learned along the way. For improved efficiency it is important to be able to access the information that has been amassed in the service desk software, but simple text queries often fall short. The purpose of this experiment is to use natural language processing techniques to extract information from a series of service desk tickets, then structure the information in such a way that it can be retrieved with more precision than is provided by simple text queries.</Text>
        </Document>
        <Document ID="26">
            <Title>Remarks</Title>
        </Document>
        <Document ID="34">
            <Title>NLP</Title>
            <Text>With preprocessing complete, the next step is natural language processing. Natural language processing is in itself a multi-stage process. First, the text data from the corpus is broken into sentences, then the sentences are broken into words. Each word is tagged for its part of speech. Next, each word is stemmed using the Lancaster stemmer provided with the Natural Language Took Kit (NLTK). In the same block where stemming occurs the program discards sentence fragments; those sentences which have either no verbs or no nouns. Named entity recognition is next run against the text to identify proper nouns. Then, phrases are created using a few simple grammar rules. The combination of phrases extracted from each service desk problem is used to represent a summary of the problem.
At this point the original problem statement of “—melenrdr - 04/11/2012 - 06:53 13-------------- _____________________________________________ From: Sevel, Evan NI/IBC-SIM Sent: Wednesday, April 11, 2012 12:13 AM To: IT-Support Schaeffler-Group North America Subject: 500 Internal Server Error When trying to access the Self Service to access my benefits and payment, I receive the error ‘500 Internal Server Error.’ Evan P. Sevel International Key Account Manager Schaeffler Group USA Inc. Mobile: 704-519-8474 E-mail: sevelean@schaeffler.com Catalog: http://medias.schaeffler.com/medias/en!hp/” would be converted into the following phrases: “server error when”, “tri”, “access the self servic”, “access, benefit and payment”, “receiv”, “the error intern server error”. These results are typical, and, on average, provide a good summary of the actual problem.</Text>
            <Comments>In script ie_proc.py</Comments>
        </Document>
        <Document ID="27">
            <Title>Information Extraction</Title>
        </Document>
        <Document ID="0">
            <Title>Essay</Title>
        </Document>
        <Document ID="35">
            <Title>Machine learning</Title>
            <Text>After the natural language processing utilities generate the summarized data, a method needs to be used to query the data. It is assumed that the above described process would be ran on any new queries, so the query value would also be formatted as above. A database is created with all of the training data, and the index of this database are the distinct phrases generated by the natural language processing. A relation between each distinct phrase and each occurrence of the phrase in a problem is established. The phrase’s importance in the sentence is calculated along with the phrase’s importance in the corpus.
When a query is performed a set is created of all the service desk problems with phrases that overlap the phrases from the query. A dynamic programming algorithm is then used to compare the the query to each of the problems in the set. (Note: the present dynamic programming algorithm is extremely simplistic; it does not use the probability of each phrase when generating a match score, it only uses ones and zeros.) If the number of matches between the two strings is greater than fifty percent of the longest string, then it is considered to be a match. This is an arbitrary number, but it seems to yield resonably precise results. More work could be done here to more scientifically balance precision and recall.</Text>
            <Comments>See script ml_basic_b.py</Comments>
        </Document>
        <Document ID="36">
            <Title>Remarks</Title>
            <Text>The contributions of each of the team members can be seen by looking at the project source repository on Github. The master commit history can be found here: https://github.com/stollcri/UA-3460-560-P2/commits/master</Text>
        </Document>
        <Document ID="3">
            <Title>Title Page</Title>
            <Text>Trouble Ticket Solution Provider
Using Natural Language Processing to Perform Information Extraction

Christopher Stoll &amp; Patrick Lemmon
Department of Computer Science
The University of Akron
Akron, Ohio, USA
</Text>
            <Notes>The &lt;$projecttitle> and &lt;$fullname> tags get replaced with the information set in Project > Meta-Data Settings… > Project Properties. You can edit those settings or just replace this text altogether.</Notes>
        </Document>
        <Document ID="21">
            <Title>Problem Statement</Title>
        </Document>
        <Document ID="29">
            <Title>Introduction</Title>
            <Text>The process begins with information extraction. The approach selected for this task is that of the cascaded finite state transducer. A batch sequential architecture is used to deterministically transform raw service desk data into clean, useful information. Each step in the sequence is described below.</Text>
        </Document>
        <Document ID="14">
            <Title>Ideas</Title>
        </Document>
        <Document ID="37">
            <Title>Design</Title>
            <Text>Since this application was experimental and it could potentially take a lot of time to process an entire corpus, it was written as a set of independent Python scripts which can be run independently from the command line. Python was chosen because that is the native language of the Natural Language Toolkit (NLTK). No interactive query interface was designed as of yet, only the train and test portions were designed in order to analyze the performance of the application.</Text>
        </Document>
        <Document ID="22">
            <Title>Approach</Title>
        </Document>
        <Document ID="15">
            <Title>Notes</Title>
        </Document>
        <Document ID="5">
            <Title>Paper directions</Title>
            <Text>abstract, problem statement, approach, results, future work

pass: 345 , fail: 363
Potential accuracy: 49% 
pass: 324 , fail: 354
Potential accuracy: 48% 
pass: 331 , fail: 409
Potential accuracy: 45% 
pass: 366 , fail: 366
Potential accuracy: 50% 
pass: 342 , fail: 413
Potential accuracy: 45% 

1.     Use Times Roman font size 12 with 1 ½ line spacing.
2.     You may include figures, tables or charts.
3.     Total number of pages is at least 4 pages, but no more than 10.
4.     Sections to be included:  
a.     Problem statement:  describe motivation and objectives of the project
b.     Approach:  basic idea of methods or structures proposed to develop the project
c.     Design and Implementation: what has been tried and implemented
d.     Results: what has been accomplished
e.     Conclusions and Future work:  what has been learned and what the next step is
f.      Remarks:  team members and their contribution to the project</Text>
        </Document>
        <Document ID="38">
            <Title>Results</Title>
            <Text>The results of this system depend greatly upon the inputs. The data for this project was provided by a large international firm and showed considerable variation between data sets. The initial test data for the system consisted of 12,729 records from a few plants in the United States. After preprocessing 5,171 records remained. Below are the testing results.

Training records
Test
records
Test
solved
Test sovled %
Group 1
4134
1037
107
10%
Group 2
4110
1061
100
9%
Group 3
4137
1034
115
11%
Group 4
4151
1020
115
11%
Group 5
4105
1066
109
10%
The second data set for the system consisted of 10,666 records from any plant in the company’s global operations. Only 3,610 records made it through the preprocessing step, yet many of those left were still not user generated records; they were made by automated or semi-automated processes. It seems that the higher solution rate is most likely due to the high percentage of machine generated tickets.

Training records
Test
records
Test
solved
Test sovled %
Group 1
2902
708
345
49%
Group 2
2932
678
324
48%
Group 3
2870
740
331
45%
Group 4
2878
732
366
50%
Group 5
2855
755
342
45%</Text>
        </Document>
        <Document ID="30">
            <Title>Remove confidential</Title>
            <Text>First, service desk tickets which are handled by strictly defined processes or potentially contain sensitive information are removed from the raw data. For example, if a user requests to have their password reset a rigid and well-known process is followed, so there is no need to provide a solution to this type of problem. Also, if the information extraction process works well, then it could be possible for people to mine confidential information, thus every attempt is made to remove records which may contain sensitive information.</Text>
            <Comments>In script ie_preproc_a.py</Comments>
        </Document>
        <Document ID="23">
            <Title>Design and Implementation</Title>
        </Document>
        <Document ID="39">
            <Title>Conclusion</Title>
            <Text>The approach taken here yields very poor results with the given corpus sizes. The number of correct solutions may improve with larger corpus sizes, but further work would need to be done to determine this. Improving the phrase matching algorithm may also help, but the biggest improvement would likely come from using a different approach.
The data sets have also been processed using Weka to check for correlations between the service desk ticket problem and the solution category. Initial tests with the second data set seem to suggest that categorization rates of better than 85% are possible. However, categorization is just one step towards providing a solution. More work needs to be done in systematically verifing the categorization rates and then providing solutions in that even more limited domain.</Text>
        </Document>
        <Document ID="8">
            <Title>Main Content</Title>
        </Document>
        <Document ID="24">
            <Title>Results</Title>
        </Document>
        <Document ID="17">
            <Title>Miscellaneous</Title>
        </Document>
        <Document ID="31">
            <Title>Remove boilerplate</Title>
            <Text>Next, boilerplate text is removed from the raw data. The people using the service desk software often write courteous notes to the users when their problems are resolved, this is good for informing the user, but it does little to help dedifferentiate individual problems. Also, email correspondences are recorded in the service desk, and these often contain the senders contact information along with the standard email header. This is also of little use in classifying the problems; if it was useful to have the user’s contact information, then it would be cleaner to pull it from a distinct field. This step also removes username information.</Text>
            <Comments>In script ie_preproc_b.py</Comments>
        </Document>
    </Documents>
</SearchIndexes>